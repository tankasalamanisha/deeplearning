{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 09:41:47.364267: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 09:41:49.854879: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-03 09:41:49.854966: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-03 09:41:50.217426: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-03 09:41:50.983984: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 09:41:50.984834: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 09:41:54.845664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadtxt(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset[:,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Just your regular densely-connected NN layer.\n",
      "\n",
      "`Dense` implements the operation:\n",
      "`output = activation(dot(input, kernel) + bias)`\n",
      "where `activation` is the element-wise activation function\n",
      "passed as the `activation` argument, `kernel` is a weights matrix\n",
      "created by the layer, and `bias` is a bias vector created by the layer\n",
      "(only applicable if `use_bias` is `True`). These are all attributes of\n",
      "`Dense`.\n",
      "\n",
      "Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      "computes the dot product between the `inputs` and the `kernel` along the\n",
      "last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
      "For example, if input has dimensions `(batch_size, d0, d1)`, then we create\n",
      "a `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\n",
      "of the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n",
      "`batch_size * d0` such sub-tensors).  The output in this case will have\n",
      "shape `(batch_size, d0, units)`.\n",
      "\n",
      "Besides, layer attributes cannot be modified after the layer has been called\n",
      "once (except the `trainable` attribute).\n",
      "When a popular kwarg `input_shape` is passed, then keras will create\n",
      "an input layer to insert before the current layer. This can be treated\n",
      "equivalent to explicitly defining an `InputLayer`.\n",
      "\n",
      "Example:\n",
      "\n",
      ">>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
      ">>> model = tf.keras.models.Sequential()\n",
      ">>> model.add(tf.keras.Input(shape=(16,)))\n",
      ">>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
      ">>> # Now the model will take as input arrays of shape (None, 16)\n",
      ">>> # and output arrays of shape (None, 32).\n",
      ">>> # Note that after the first layer, you don't need to specify\n",
      ">>> # the size of the input anymore:\n",
      ">>> model.add(tf.keras.layers.Dense(32))\n",
      ">>> model.output_shape\n",
      "(None, 32)\n",
      "\n",
      "Args:\n",
      "    units: Positive integer, dimensionality of the output space.\n",
      "    activation: Activation function to use.\n",
      "        If you don't specify anything, no activation is applied\n",
      "        (ie. \"linear\" activation: `a(x) = x`).\n",
      "    use_bias: Boolean, whether the layer uses a bias vector.\n",
      "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      "    bias_initializer: Initializer for the bias vector.\n",
      "    kernel_regularizer: Regularizer function applied to\n",
      "        the `kernel` weights matrix.\n",
      "    bias_regularizer: Regularizer function applied to the bias vector.\n",
      "    activity_regularizer: Regularizer function applied to\n",
      "        the output of the layer (its \"activation\").\n",
      "    kernel_constraint: Constraint function applied to\n",
      "        the `kernel` weights matrix.\n",
      "    bias_constraint: Constraint function applied to the bias vector.\n",
      "\n",
      "Input shape:\n",
      "    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      "    The most common situation would be\n",
      "    a 2D input with shape `(batch_size, input_dim)`.\n",
      "\n",
      "Output shape:\n",
      "    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      "    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      "    the output would have shape `(batch_size, units)`.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.python/current/lib/python3.10/site-packages/keras/src/layers/core/dense.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "layer_1 = Dense(units=12, input_shape=(8,), activation=\"relu\")\n",
    "layer_2 = Dense(units=8, activation=\"relu\")\n",
    "layer_3 = Dense(units=1, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=layer_1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = layer_2(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = layer_3(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(768, 12), dtype=float32, numpy=\n",
       "array([[  0.      , 109.93961 ,  57.91752 , ...,  14.385197,   0.      ,\n",
       "         72.143524],\n",
       "       [  0.      ,  72.63017 ,  44.765278, ...,   0.      ,   0.      ,\n",
       "         46.772392],\n",
       "       [  0.      , 126.06733 ,  33.6356  , ...,  28.231182,   6.866677,\n",
       "         77.814415],\n",
       "       ...,\n",
       "       [  0.      ,  75.293465,  45.340965, ...,  24.712992,  43.632435,\n",
       "         65.009254],\n",
       "       [  0.      ,  96.537575,  44.936428, ...,  26.971537,   7.61604 ,\n",
       "         68.39608 ],\n",
       "       [  0.      ,  78.466774,  42.827263, ...,   0.      ,   0.      ,\n",
       "         46.703716]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1  #12 neural networks, thus 12 activation values for 768 input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.      , 109.93961 ,  57.91752 , ...,  14.385197,   0.      ,\n",
       "         72.143524],\n",
       "       [  0.      ,  72.63017 ,  44.765278, ...,   0.      ,   0.      ,\n",
       "         46.772392],\n",
       "       [  0.      , 126.06733 ,  33.6356  , ...,  28.231182,   6.866677,\n",
       "         77.814415],\n",
       "       ...,\n",
       "       [  0.      ,  75.293465,  45.340965, ...,  24.712992,  43.632435,\n",
       "         65.009254],\n",
       "       [  0.      ,  96.537575,  44.936428, ...,  26.971537,   7.61604 ,\n",
       "         68.39608 ],\n",
       "       [  0.      ,  78.466774,  42.827263, ...,   0.      ,   0.      ,\n",
       "         46.703716]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.      , 109.93961 ,  57.91752 ,  36.786316,   0.      ,\n",
       "        71.90008 ,   0.      ,  35.9738  ,  12.365368,  14.385197,\n",
       "         0.      ,  72.143524], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.numpy()[0]   # Each row-vector has 12 entries indicating 12 activation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(768, 8), dtype=float32, numpy=\n",
       "array([[ 0.      ,  0.      , 32.64112 , ..., 55.412437, 69.36698 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 36.07628 , ..., 39.20076 , 31.862494,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 16.45094 , ..., 60.415226, 84.08001 ,\n",
       "         0.      ],\n",
       "       ...,\n",
       "       [ 0.      ,  0.      ,  0.      , ..., 28.705746, 76.02812 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 27.229465, ..., 41.169243, 59.04902 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 39.766903, ..., 44.75812 , 31.104065,\n",
       "         0.      ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      , 32.64112 , ..., 55.412437, 69.36698 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 36.07628 , ..., 39.20076 , 31.862494,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 16.45094 , ..., 60.415226, 84.08001 ,\n",
       "         0.      ],\n",
       "       ...,\n",
       "       [ 0.      ,  0.      ,  0.      , ..., 28.705746, 76.02812 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 27.229465, ..., 41.169243, 59.04902 ,\n",
       "         0.      ],\n",
       "       [ 0.      ,  0.      , 39.766903, ..., 44.75812 , 31.104065,\n",
       "         0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.      ,  0.      , 32.64112 ,  0.      , 22.837307, 55.412437,\n",
       "       69.36698 ,  0.      ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.numpy()[0]# Each row-vector has 8 entries indicating 12 activation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(768, 1), dtype=float32, numpy=\n",
       "array([[1.00000000e+00],\n",
       "       [3.48752365e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.05677862e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99907494e-01],\n",
       "       [2.33048975e-12],\n",
       "       [9.99992967e-01],\n",
       "       [9.99994993e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.50004591e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.36652840e-07],\n",
       "       [9.99999285e-01],\n",
       "       [3.92727926e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.89581704e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.10741407e-08],\n",
       "       [1.43795788e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.18370261e-11],\n",
       "       [9.49332416e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.25562775e-01],\n",
       "       [2.87208427e-03],\n",
       "       [1.71674216e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.89000158e-05],\n",
       "       [9.92929745e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.45004607e-11],\n",
       "       [4.68314480e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.94205654e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.48249969e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.26412734e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.77645278e-01],\n",
       "       [1.49039323e-08],\n",
       "       [1.00000000e+00],\n",
       "       [8.28743041e-01],\n",
       "       [2.86983013e-05],\n",
       "       [6.48978471e-08],\n",
       "       [2.50076959e-09],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.40628992e-07],\n",
       "       [1.00000000e+00],\n",
       "       [2.93549278e-12],\n",
       "       [1.47893725e-10],\n",
       "       [3.08582118e-11],\n",
       "       [6.79378118e-08],\n",
       "       [1.00000000e+00],\n",
       "       [2.95421630e-01],\n",
       "       [9.99999642e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.14000361e-03],\n",
       "       [7.65040090e-14],\n",
       "       [1.00000000e+00],\n",
       "       [5.06212890e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.62222136e-03],\n",
       "       [9.44833329e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.25059557e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.90185654e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99877691e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.51389363e-08],\n",
       "       [9.96364832e-01],\n",
       "       [6.38920084e-10],\n",
       "       [1.00000000e+00],\n",
       "       [7.78006405e-20],\n",
       "       [1.00000000e+00],\n",
       "       [3.46934885e-01],\n",
       "       [3.10914894e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.38773453e-01],\n",
       "       [2.25407470e-09],\n",
       "       [1.00000000e+00],\n",
       "       [9.94408548e-01],\n",
       "       [5.32153398e-02],\n",
       "       [1.18100819e-04],\n",
       "       [7.00265775e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.01702654e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999404e-01],\n",
       "       [2.90065259e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.49934366e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99480128e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.55296189e-09],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [5.12267696e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99974430e-01],\n",
       "       [7.30900283e-08],\n",
       "       [1.00000000e+00],\n",
       "       [4.96096194e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.01138127e-01],\n",
       "       [3.95508089e-13],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999881e-01],\n",
       "       [1.13135073e-07],\n",
       "       [1.00000000e+00],\n",
       "       [9.96045172e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999702e-01],\n",
       "       [1.02914292e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999166e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.59045112e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.52746691e-04],\n",
       "       [1.24925791e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99973238e-01],\n",
       "       [5.13667524e-01],\n",
       "       [2.27954960e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.49816084e-08],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99953866e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.98771311e-08],\n",
       "       [1.00000000e+00],\n",
       "       [4.58848774e-01],\n",
       "       [7.00647288e-05],\n",
       "       [1.14070104e-08],\n",
       "       [1.00000000e+00],\n",
       "       [8.87928533e-12],\n",
       "       [4.99476187e-07],\n",
       "       [9.99742210e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.19011235e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [8.88634503e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.88105851e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.03728219e-07],\n",
       "       [2.32225084e-05],\n",
       "       [3.46605219e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.13508874e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.38950013e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.63185068e-05],\n",
       "       [1.12964436e-02],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.73288929e-08],\n",
       "       [5.20678498e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99997675e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.09725362e-03],\n",
       "       [1.17004562e-09],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999225e-01],\n",
       "       [1.25468915e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.10905699e-01],\n",
       "       [1.30804330e-02],\n",
       "       [9.99567926e-01],\n",
       "       [9.99497294e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.34245574e-01],\n",
       "       [9.99839067e-01],\n",
       "       [2.14254120e-04],\n",
       "       [7.12876772e-06],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999940e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.88191426e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.63736721e-09],\n",
       "       [9.99917328e-01],\n",
       "       [1.60840646e-04],\n",
       "       [9.99999702e-01],\n",
       "       [9.07031339e-09],\n",
       "       [1.00000000e+00],\n",
       "       [7.17343912e-02],\n",
       "       [9.99762833e-01],\n",
       "       [4.19088081e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.12740497e-06],\n",
       "       [9.99977171e-01],\n",
       "       [9.90559757e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.63501453e-01],\n",
       "       [6.70795918e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.16864865e-10],\n",
       "       [1.00000000e+00],\n",
       "       [5.65078437e-01],\n",
       "       [5.65522254e-01],\n",
       "       [6.28891170e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.37635005e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.98880744e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.84020925e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99960005e-01],\n",
       "       [2.33212523e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.24593873e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99893188e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.55369782e-01],\n",
       "       [1.97781829e-17],\n",
       "       [9.99998689e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.30950633e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.12800432e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.78253104e-04],\n",
       "       [9.67023969e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.20802076e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.97704208e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.38487145e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.68138312e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99970555e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.13288078e-14],\n",
       "       [4.11900317e-07],\n",
       "       [4.04926948e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.20665979e-17],\n",
       "       [3.02672167e-13],\n",
       "       [2.51509040e-03],\n",
       "       [1.15289248e-13],\n",
       "       [9.99999881e-01],\n",
       "       [8.69339306e-15],\n",
       "       [9.99990880e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.30905095e-12],\n",
       "       [9.99998689e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.93940163e-01],\n",
       "       [1.59286652e-02],\n",
       "       [9.99995172e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.77912667e-01],\n",
       "       [9.99748588e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.18465757e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.55781673e-02],\n",
       "       [5.53613741e-13],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [8.78255069e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.98068035e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.91889775e-01],\n",
       "       [1.37149968e-07],\n",
       "       [1.00000000e+00],\n",
       "       [5.71120618e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.05870745e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.69425333e-01],\n",
       "       [4.24545482e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.02000743e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.65668698e-05],\n",
       "       [5.79713166e-01],\n",
       "       [7.41193753e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.19657797e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99998510e-01],\n",
       "       [9.77642119e-01],\n",
       "       [1.19722165e-04],\n",
       "       [1.00000000e+00],\n",
       "       [4.09540832e-01],\n",
       "       [9.89059150e-01],\n",
       "       [2.31178463e-04],\n",
       "       [3.24857051e-11],\n",
       "       [9.97464418e-01],\n",
       "       [9.99998808e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.68187509e-03],\n",
       "       [8.81201386e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.91708922e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.62018403e-07],\n",
       "       [9.99993503e-01],\n",
       "       [2.05554116e-07],\n",
       "       [9.64145919e-09],\n",
       "       [1.00000000e+00],\n",
       "       [9.99980032e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.61925529e-02],\n",
       "       [9.91697252e-01],\n",
       "       [4.45337873e-03],\n",
       "       [2.60630131e-01],\n",
       "       [4.49124500e-02],\n",
       "       [9.99671340e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.98184085e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.94254891e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.32526070e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.18786142e-12],\n",
       "       [1.81882700e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.09219584e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [5.01325814e-10],\n",
       "       [2.84840477e-14],\n",
       "       [1.00000000e+00],\n",
       "       [3.16769331e-07],\n",
       "       [1.30871407e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99963284e-01],\n",
       "       [6.62464372e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.71411407e-01],\n",
       "       [9.61575279e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.38135871e-03],\n",
       "       [1.61983407e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.97706413e-01],\n",
       "       [9.80464578e-01],\n",
       "       [8.07175878e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.92124951e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.98260609e-11],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.87827111e-08],\n",
       "       [9.93344665e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.04723981e-07],\n",
       "       [1.68352693e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.92291868e-01],\n",
       "       [2.82855015e-02],\n",
       "       [1.00000000e+00],\n",
       "       [4.52217013e-01],\n",
       "       [9.99999940e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.92823791e-06],\n",
       "       [9.65163112e-01],\n",
       "       [6.11384574e-04],\n",
       "       [6.75190037e-08],\n",
       "       [9.77065921e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.10626187e-11],\n",
       "       [1.00000000e+00],\n",
       "       [4.34176647e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.21267999e-08],\n",
       "       [2.48894196e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.74338413e-10],\n",
       "       [9.99868333e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.37088985e-04],\n",
       "       [9.89795923e-01],\n",
       "       [9.99468565e-01],\n",
       "       [7.29851877e-07],\n",
       "       [1.00000000e+00],\n",
       "       [4.32468690e-02],\n",
       "       [9.99992371e-01],\n",
       "       [1.56185720e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.62182362e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.43821850e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.88456465e-13],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.23215216e-09],\n",
       "       [1.00000000e+00],\n",
       "       [7.75521457e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.72775638e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.40639495e-08],\n",
       "       [1.00000000e+00],\n",
       "       [1.20377059e-04],\n",
       "       [8.94281094e-10],\n",
       "       [1.36785721e-03],\n",
       "       [1.25462199e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.95460657e-07],\n",
       "       [9.98365104e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.14590288e-04],\n",
       "       [9.95909750e-01],\n",
       "       [4.99491215e-01],\n",
       "       [2.11352686e-04],\n",
       "       [6.97618648e-02],\n",
       "       [1.93271029e-04],\n",
       "       [9.06110287e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.51754338e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.02473521e-03],\n",
       "       [1.65445637e-03],\n",
       "       [3.29034068e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.17304744e-02],\n",
       "       [9.99968827e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.16935372e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99751151e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.76774048e-09],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99848962e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99998391e-01],\n",
       "       [8.41571271e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.64723992e-02],\n",
       "       [5.25850680e-07],\n",
       "       [1.00000000e+00],\n",
       "       [3.32155963e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999464e-01],\n",
       "       [1.86253328e-06],\n",
       "       [9.80503559e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99985993e-01],\n",
       "       [9.48306859e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.72827599e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.98602211e-01],\n",
       "       [9.99510586e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.80313684e-05],\n",
       "       [2.41743106e-08],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.45178142e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.41615884e-07],\n",
       "       [1.00000000e+00],\n",
       "       [9.93130326e-01],\n",
       "       [9.99994695e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.42378703e-14],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999702e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99998033e-01],\n",
       "       [9.99821126e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.76196874e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [4.16090935e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.25919095e-05],\n",
       "       [2.52357857e-12],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [5.82255355e-09],\n",
       "       [9.50878384e-05],\n",
       "       [1.00000000e+00],\n",
       "       [3.86992795e-03],\n",
       "       [9.99982893e-01],\n",
       "       [2.42110621e-03],\n",
       "       [1.00000000e+00],\n",
       "       [2.32325206e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.36110806e-01],\n",
       "       [2.10946100e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.99080710e-10],\n",
       "       [1.00000000e+00],\n",
       "       [1.02938918e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.95406347e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.83785616e-07],\n",
       "       [9.99693811e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [5.05054295e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.37334585e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999166e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.65632647e-02],\n",
       "       [9.00502384e-01],\n",
       "       [3.68726538e-09],\n",
       "       [1.00000000e+00],\n",
       "       [8.43081653e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.90286262e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.78903136e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99998093e-01],\n",
       "       [3.97970354e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3 # 1 activation value for 768 input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layer_1)\n",
    "model.add(layer_2)\n",
    "model.add(layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 6.7356 - accuracy: 0.5456\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.0125 - accuracy: 0.4154\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4.4269 - accuracy: 0.3841\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.4782 - accuracy: 0.4766\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.9106 - accuracy: 0.5195\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.4852 - accuracy: 0.4922\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.2700 - accuracy: 0.4922\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.1004 - accuracy: 0.4896\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.8994 - accuracy: 0.4961\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6988 - accuracy: 0.5013\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5114 - accuracy: 0.5104\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3397 - accuracy: 0.5195\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2296 - accuracy: 0.5339\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1358 - accuracy: 0.5417\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0731 - accuracy: 0.5430\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0223 - accuracy: 0.5534\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9843 - accuracy: 0.5586\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9477 - accuracy: 0.5664\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9193 - accuracy: 0.5820\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8965 - accuracy: 0.5781\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8746 - accuracy: 0.5807\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8443 - accuracy: 0.5938\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8241 - accuracy: 0.5872\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8094 - accuracy: 0.5951\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.5898\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7730 - accuracy: 0.6029\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.6120\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7473 - accuracy: 0.5951\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.6133\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6068\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.6120\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.6237\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.6237\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.6302\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.6289\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.6354\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.6484\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.6393\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6367\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6328\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6576\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6406\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6510\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6562\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6693\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6615\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6901\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6771\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6758\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.6758\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6797\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.6940\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6810\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6940\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5959 - accuracy: 0.6966\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.6901\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.6953\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6914\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5882 - accuracy: 0.6979\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.6927\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6992\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6953\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6940\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6940\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7005\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6979\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.6966\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6979\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6966\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.6940\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7018\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.6979\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7018\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.6953\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.6979\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.6953\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7070\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.6966\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7057\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.6901\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7057\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.6992\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7044\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7018\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7096\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.6940\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7005\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6888\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7096\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7031\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7031\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7096\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7005\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7109\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7005\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5576 - accuracy: 0.7083\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7044\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7096\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7083\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7109\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5586 - accuracy: 0.7005\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7096\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7005\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.7070\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7174\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.6979\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7214\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7031\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7083\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.6979\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7174\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7070\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7070\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7174\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5530 - accuracy: 0.7044\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7214\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7018\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7135\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7005\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7148\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7188\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.6979\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.7188\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7044\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.7174\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7044\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7240\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7018\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7292\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7005\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7148\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7096\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7135\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7135\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.7057\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7122\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.7201\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7096\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7214\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7253\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7148\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5457 - accuracy: 0.7174\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7174\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7096\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7240\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7174\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7031\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7253\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7161\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.7201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff1cb589c90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=150, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 896us/step - loss: 0.5392 - accuracy: 0.7161\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.61458134651184"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
