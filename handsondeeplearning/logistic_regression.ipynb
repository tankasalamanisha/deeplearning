{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399d9b68",
   "metadata": {},
   "source": [
    "## A comparitive notebook for implimenting Logistic Regression: Traditional ML vs Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a2682",
   "metadata": {},
   "source": [
    "### Vectorizing Logistic Regression\n",
    "\n",
    "In this notebook, we shall first delve into what happens in logistic regression algorithm and understand if parts of it can be vectorized. Once we understand it, we get into learning how to vectorize gradient descent output in Logistic Regression. The step further would be our comparitive implimentation of Logistic regression using traditional ML and Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00656334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non vectorised approach\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialization\n",
    "m = 1000 # number of examples\n",
    "n= 5 # number of features\n",
    "W = np.random.randn(n,1) * 0.01 # weights\n",
    "b = 0 # bias\n",
    "X = np.random.randn(n,m) # input data\n",
    "Y = np.random.randint(0,2,size=(1,m)) # labels\n",
    "alpha = 0.01 # learning rate\n",
    "\n",
    "# Forward pass and backward pass initialization\n",
    "dW = np.zeros((n,1))\n",
    "db = 0\n",
    "cost = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60e749",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
